{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Agents\n",
    "\n",
    "In this assignment, your task is to implement ... The algorithms are a recap from your earlier Algorithms and Data Structures class, but the input is slightly different: the graph is not materialized. Instead, it is generated dynamically and you can access a single node of the graph at a time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by considering a generic problem-solving agent. The agent receives *percepts* from its *environment* through *sensors* and uses *actuators* to perform *actions* to influence the environment. The process of converting the percepts to the actions (denoted by the question mark in the picture below) is the core function of the agent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](aima-images/fig2_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This picture is very general and covers a broad range of agents, both software (e.g., a chatbot) and hardware (e.g., a robot vacuum cleaner). For now, we will simplify. We will ignore sensors and actuators and concentrate only on the core. We will implement it according to the following contract represented as the class `Agent` (see cell below) with a single method: `do_step`. The sole argument of the method are the percepts of the agent and it should return an action to be executed next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def next_action(self, percepts):\n",
    "        ...\n",
    "        return action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The environment above represents a real environment, meaning that any action in it will be visible to the user. Usually, it makes it unsuitable for planning what action to take. For example, if one plans to go on a car trip from Poznań to Berlin, one does not start driving blindly trying to find a route to Berlin. Instead, one takes a map and search for it on a model of the environment. We will combine this model with the definition of the problem to be solved, i.e., a starting position and a destination.\n",
    "\n",
    "This is represented by the class `Problem` below. It has a single property `initial_state` that returns the starting position in the problem, e.g., the city of Poznań in the example about the trip. There are also three methods:\n",
    "* `available_actions` returns, for a given `state` (e.g., a currently considered city), what actions are to be considered (e.g., what are the neighbouring cities one could go to directly from the currently considered city)\n",
    "* `do_action` returns new state reached from the state `state` by executing the action `action` (e.g., the state representing that begin in Poznań and taking the highway to Warsaw, one ends up in Warsaw)\n",
    "* `is_goal` which returns `True` if `state` is (one of) the destination(s) for the agent in this particular problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Problem:\n",
    "    @property\n",
    "    def initial_state(self):\n",
    "        ...\n",
    "        \n",
    "    def available_actions(self, state):\n",
    "        ...        \n",
    "        \n",
    "    def do_action(self, state, action):\n",
    "        ...\n",
    "        return new_state\n",
    "    \n",
    "    def is_goal(self, state) -> bool:\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ground the problem definition in something more concrete consider a small flat of two dirty rooms and a robotic vacuum cleaner, as depicted in the following picture:\n",
    "![](aima-images/fig2_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the model, there are two rooms (A, B), each of them is either dirty or clean and the robot can always go to the left or to the right (maybe bumping into a wall), or suck the dirt (even if there's no dirt).\n",
    "\n",
    "This is a model. Maybe the real environment is similar: two very small, rectangular rooms such that a single \"suck\" of the robot cleans the whole room at a time. Maybe it is very dissimilary: there are more rooms and they're of varying shapes, and actually cleaning them is a tedious task. The agent doesn't know and must thus assume that the `Problem` represents the environment well enough.\n",
    "\n",
    "Assume the initial state looks like the picture above, and there are two goal states: both rooms clean and robot in either room A or room B. Lets formalize all this into the class `VacuumProblem`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VacuumProblem(Problem):\n",
    "    @property\n",
    "    def initial_state(self):\n",
    "        return (0, (True, True))\n",
    "    \n",
    "    def available_actions(self, state):\n",
    "        return [\"Left\", \"Suck\", \"Right\"]\n",
    "        \n",
    "    def do_action(self, state, action):\n",
    "        robot, dirty = state\n",
    "        if action == \"Left\":\n",
    "            return (max(robot-1, 0), dirty)\n",
    "        elif action == \"Suck\":\n",
    "            new_dirty = list(dirty)\n",
    "            new_dirty[robot] = False\n",
    "            return (robot, tuple(new_dirty))\n",
    "        elif action == \"Right\":\n",
    "            return (min(robot+1, len(dirty)-1), dirty)        \n",
    "        raise Exception('Invalid action')\n",
    "    \n",
    "    def is_goal(self, state) -> bool:\n",
    "        return not any(state[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets test it a bit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State after going right from the initial state (1, (True, True))\n",
      "Are we there yet? False\n"
     ]
    }
   ],
   "source": [
    "problem = VacuumProblem()\n",
    "state = problem.initial_state\n",
    "state = problem.do_action(state, 'Right')\n",
    "\n",
    "print(\"State after going right from the initial state\", state)\n",
    "print(\"Are we there yet?\", problem.is_goal(state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State after going right again (1, (True, True))\n",
      "Are we there yet? False\n"
     ]
    }
   ],
   "source": [
    "state = problem.do_action(state, 'Right')\n",
    "\n",
    "print(\"State after going right again\", state)\n",
    "print(\"Are we there yet?\", problem.is_goal(state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State after sucking (1, (True, False))\n",
      "Are we there yet? False\n"
     ]
    }
   ],
   "source": [
    "state = problem.do_action(state, 'Suck')\n",
    "\n",
    "print(\"State after sucking\", state)\n",
    "print(\"Are we there yet?\", problem.is_goal(state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State after going to the left twice and sucking (0, (False, False))\n",
      "Are we there yet? True\n"
     ]
    }
   ],
   "source": [
    "state = problem.do_action(state, 'Left')\n",
    "state = problem.do_action(state, 'Left')\n",
    "state = problem.do_action(state, 'Suck')\n",
    "\n",
    "print(\"State after going to the left twice and sucking\", state)\n",
    "print(\"Are we there yet?\", problem.is_goal(state))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oracular agent\n",
    "\n",
    "Consider the following oracular agent. It is initialized with a problem and has an embedded oracle, which provides it with a sequence of actions to be executed to reach a goal in the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OracularAgent(Agent):\n",
    "    def __init__(self, problem):\n",
    "        self.problem = problem\n",
    "        self.plan = self.oracle()\n",
    "        \n",
    "    def next_action(self, percepts):\n",
    "        return self.plan.pop(0)\n",
    "    \n",
    "    def oracle(self):\n",
    "        return ['Suck', 'Right', 'Suck']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is the time to test this agent. We create an instance of the `VacuumProblem` and then ask the agent for `next_action`s until goal is not reach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached state: (1, (False, False))\n",
      "Is it goal? True\n"
     ]
    }
   ],
   "source": [
    "problem = VacuumProblem()\n",
    "agent = OracularAgent(problem)\n",
    "\n",
    "state = problem.initial_state\n",
    "while not problem.is_goal(state):\n",
    "    action = agent.next_action(None)\n",
    "    state = problem.do_action(state, action)\n",
    "    \n",
    "print(\"Reached state:\", state)\n",
    "print(\"Is it goal?\", problem.is_goal(state))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that the agent works remarkably well and is able to reach a goal state with no problem whatsoever. It is fast, the code is short. There is only one obvious drawback: the solution is hard-coded and completely unsuitable not only to other types of problems, but also for other variants of the vacuum problem, e.g., such that the robot must return to the room A. We must therefore look for a more general solution: a searching agent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Implement a breadth-first searching agent\n",
    "\n",
    "Complete the method `bfs` in the class `BFSAgent` in the next cell. It should implement breadth-first search, an algorithm you should be familar with after the *Algorithms and data structures* classes. The main difference is that the graph is not explicitly specified not available as a whole. Instead, you must look on the `Problem` as a graph generator: a state corresponds to a node in the graph and each action available in the state corresponds to an arc from the current state to the state reached by executing this action. The following picture should help you to understand the concept.\n",
    "\n",
    "![](aima-images/fig3_3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BFSAgent(Agent):\n",
    "    def __init__(self, problem):\n",
    "        self.problem = problem\n",
    "        self.plan = self.bfs()\n",
    "        \n",
    "    def next_action(self, percepts):\n",
    "        return self.plan.pop(0)\n",
    "    \n",
    "    def bfs(self):\n",
    "        queue_of_paths = deque()\n",
    "        current_path = ()\n",
    "        current_state = self.problem.initial_state\n",
    "        visited_states= {current_state}\n",
    "        \n",
    "        queue_of_paths.append( (current_state, current_path) )\n",
    "        \n",
    "        #in this version to save memory BFS doesn't expand nodes which visited SOMEWHERE in the graph\n",
    "        \n",
    "        while not self.problem.is_goal(current_state) and queue_of_paths:\n",
    "            \n",
    "            for move in self.problem.available_actions(current_state):\n",
    "                new_state = self.problem.do_action(current_state, move)\n",
    "                if new_state not in visited_states:\n",
    "                    #print(\"wow you haven't been here\")\n",
    "                    new_path = list(current_path)\n",
    "                    new_path.append(move)\n",
    "                    visited_states.add(new_state)\n",
    "                    visited_states.add(new_state)\n",
    "                        \n",
    "                    queue_of_paths.append( (new_state, tuple(new_path)) )\n",
    "                    \n",
    "            current_state, current_path = queue_of_paths.popleft()\n",
    "            \n",
    "        return list(current_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets test the solution in the same framework as the oracular agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plan to be executed ['Suck', 'Right', 'Suck']\n",
      "Reached state: (1, (False, False))\n",
      "Is it goal? True\n"
     ]
    }
   ],
   "source": [
    "problem = VacuumProblem()\n",
    "agent = BFSAgent(problem)\n",
    "\n",
    "print(\"Plan to be executed\", agent.plan)\n",
    "\n",
    "state = problem.initial_state\n",
    "while not problem.is_goal(state):\n",
    "    action = agent.next_action(None)\n",
    "    state = problem.do_action(state, action)\n",
    "    \n",
    "print(\"Reached state:\", state)\n",
    "print(\"Is it goal?\", problem.is_goal(state))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Implementing depth-first searching agent\n",
    "\n",
    "Complete the method `dfs` in the class `BFSAgent` in the next cell. This time the task is to implement depth-first search (DFS). Be careful: DFS is vulnerable to infinite loops. Implement some sort of protection against them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DFSAgent(Agent):\n",
    "    def __init__(self, problem):\n",
    "        self.problem = problem\n",
    "        self.plan = self.dfs()\n",
    "        \n",
    "    def next_action(self, percepts):\n",
    "        return self.plan.pop(0)\n",
    "    \n",
    "    def dfs(self): \n",
    "        list_of_occured_states = [self.problem.initial_state]\n",
    "        visited_states = {list_of_occured_states[-1]}\n",
    "        path = []\n",
    "        \n",
    "        self.dfs_recurrence(list_of_occured_states, path, visited_states)\n",
    "        return path\n",
    "    \n",
    "    def dfs_recurrence(self, list_of_occured_states, path, visited_states):\n",
    "        for move in self.problem.available_actions(list_of_occured_states[-1]):\n",
    "            \n",
    "            if self.problem.is_goal(list_of_occured_states[-1]) or len(path) > 100:\n",
    "#                 When there wasn't path length limit the kernel starts raising the recursion error\n",
    "                return\n",
    "            \n",
    "            new_state = self.problem.do_action(list_of_occured_states[-1], move)\n",
    "            \n",
    "#             print(\"\\ncurrent path: \", path,\n",
    "#                   \"\\ncurrent move: \", move,\n",
    "#                   \"\\ncurrent state: \", new_state)\n",
    "\n",
    "            if new_state not in visited_states:\n",
    "                path.append(move)\n",
    "                list_of_occured_states.append(new_state)\n",
    "                visited_states.add(new_state)\n",
    "                \n",
    "                self.dfs_recurrence(list_of_occured_states, path, visited_states)\n",
    "                \n",
    "                if not self.problem.is_goal(list_of_occured_states[-1]):\n",
    "                    path.pop()\n",
    "                    list_of_occured_states.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plan to be executed ['Suck', 'Right', 'Suck']\n",
      "Reached state: (1, (False, False))\n",
      "Is it goal? True\n"
     ]
    }
   ],
   "source": [
    "problem = VacuumProblem()\n",
    "agent = DFSAgent(problem)\n",
    "\n",
    "print(\"Plan to be executed\", agent.plan)\n",
    "\n",
    "state = problem.initial_state\n",
    "while not problem.is_goal(state):\n",
    "    action = agent.next_action(None)\n",
    "    state = problem.do_action(state, action)\n",
    "    \n",
    "print(\"Reached state:\", state)\n",
    "print(\"Is it goal?\", problem.is_goal(state))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Test it on 8-puzzle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 8-puzzle, an instance of which is shown in the figure, consists of a 3×3 board with\n",
    "eight numbered tiles and a blank space. A tile adjacent to the blank space can slide into the space. The object is to reach a specified goal state, such as the one shown on the right of the figure. The standard formulation is as follows:\n",
    "\n",
    "* *States*: A state description specifies the location of each of the eight tiles and the blank in one of the nine squares.\n",
    "* *Initial state*: Any state can be designated as the initial state. Note that any given goal can be reached from exactly half of the possible initial states.\n",
    "* *Actions*: The simplest formulation defines the actions as movements of the blank space Left, Right, Up, or Down. Different subsets of these are possible depending on where the blank is.\n",
    "* *Transition model*: Given a state and action, this returns the resulting state; for example, if we apply Left to the start state in the figure, the resulting state has the 5 and the blank switched.\n",
    "* *Goal test*: This checks whether the state matches the goal configuration shown in the figure. (Other goal configurations are possible.)\n",
    "\n",
    "![](aima-images/fig3_4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your task is to implement `PuzzleProblem` as a subclass of the class `Problem` to provide a formal problem description of the 8-puzzle problem described above. Then test your `DFSAgent` and `BFSAgent` on this new problem. \n",
    "\n",
    "It's fine if your agents are incapable of solving the problem for the presented start state and goal due to the excessive length of the necessary plan. If this the case, simplify the problem by changing the start state and/or the goal. The idea of this task is to show that your implementations are correct and the agents are capable - in principle - of solving this problem, not waiting for hours on end for computations to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PuzzleProblem(Problem):\n",
    "    @property\n",
    "    def initial_state(self):\n",
    "        \"\"\"1st component of state:\n",
    "        - the (row, col) of where the blank tile (the zero tile) is\n",
    "        2nd component:\n",
    "        -3x3 matrix representing the board and the arrangement of tiles\"\"\"\n",
    "        return ((1,1),((7,2,4),(5,0,6),(8,3,1)))\n",
    "        \n",
    "    def available_actions(self, state):\n",
    "        position, board = state\n",
    "        row_of_blank, col_of_blank = position\n",
    "        actions = []\n",
    "        \n",
    "        if row_of_blank - 1 >= 0:\n",
    "            actions.append(\"Up\")\n",
    "        if row_of_blank + 1 <= 2:\n",
    "            actions.append(\"Down\")\n",
    "        if col_of_blank - 1 >= 0:\n",
    "            actions.append(\"Left\")\n",
    "        if col_of_blank + 1 <= 2:\n",
    "            actions.append(\"Right\")\n",
    "\n",
    "        return actions\n",
    "        \n",
    "    def do_action(self, state, action):\n",
    "        blank_coords, matrix_of_board = state\n",
    "#         print(blank_coords, action, state)\n",
    "        table_of_action_encoding = {'Left':(0, -1),\n",
    "                                 'Right':(0, 1),\n",
    "                                 'Up':(-1,0),\n",
    "                                 'Down':(1,0)}\n",
    "        action_encoding = table_of_action_encoding[action]\n",
    "        \n",
    "        new_blank_coords = tuple([blank_coords[i] + action_encoding[i] for i in range(len(blank_coords))])\n",
    "#         print(new_blank_coords, \" new blank\")\n",
    "        mutable_board = [list(matrix_of_board[i]) for i in range(len(matrix_of_board))]\n",
    "    \n",
    "        value_at_new_blank_position = matrix_of_board[new_blank_coords[0]][new_blank_coords[1]]\n",
    "        \n",
    "        mutable_board[new_blank_coords[0]][new_blank_coords[1]] = 0\n",
    "        \n",
    "        mutable_board[blank_coords[0]][blank_coords[1]] = value_at_new_blank_position\n",
    "        \n",
    "        modified_board = tuple([tuple(mutable_board[i]) for i in range(len(mutable_board))])\n",
    "        \n",
    "        new_state = (new_blank_coords, modified_board)\n",
    "        return new_state\n",
    "    \n",
    "    def is_goal(self, state) -> bool:\n",
    "        return ((0,0),((0,1,2),(3,4,5),(6,7,8))) == state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plan lenght:  26\n",
      "Plan to be executed ['Left', 'Up', 'Right', 'Down', 'Down', 'Left', 'Up', 'Right', 'Right', 'Up', 'Left', 'Left', 'Down', 'Right', 'Right', 'Down', 'Left', 'Up', 'Right', 'Up', 'Left', 'Down', 'Down', 'Left', 'Up', 'Up']\n",
      "Reached state: ((0, 0), ((0, 1, 2), (3, 4, 5), (6, 7, 8)))\n",
      "Is it goal? True\n"
     ]
    }
   ],
   "source": [
    "problem = PuzzleProblem()\n",
    "# print(problem.initial_state[0][])\n",
    "# %timeit agent = BFSAgent(problem)\n",
    "agent = BFSAgent(problem)\n",
    "\n",
    "print(\"Plan lenght: \", len(agent.plan))\n",
    "\n",
    "print(\"Plan to be executed\", agent.plan)\n",
    "\n",
    "state = problem.initial_state\n",
    "\n",
    "while not problem.is_goal(state) and agent.plan:\n",
    "    action = agent.next_action(None)\n",
    "    state = problem.do_action(state, action)\n",
    "    \n",
    "print(\"Reached state:\", state)\n",
    "print(\"Is it goal?\", problem.is_goal(state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "233 ms ± 6.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "Plan lenght:  96\n",
      "Plan to be executed ['Up', 'Left', 'Down', 'Down', 'Right', 'Up', 'Up', 'Left', 'Down', 'Down', 'Right', 'Up', 'Up', 'Left', 'Down', 'Down', 'Right', 'Up', 'Up', 'Left', 'Down', 'Down', 'Right', 'Up', 'Up', 'Left', 'Down', 'Down', 'Right', 'Right', 'Up', 'Up', 'Left', 'Down', 'Down', 'Left', 'Up', 'Up', 'Right', 'Down', 'Down', 'Left', 'Up', 'Up', 'Right', 'Down', 'Down', 'Left', 'Up', 'Up', 'Right', 'Down', 'Down', 'Left', 'Up', 'Up', 'Right', 'Down', 'Down', 'Left', 'Up', 'Right', 'Up', 'Left', 'Down', 'Down', 'Right', 'Up', 'Up', 'Left', 'Down', 'Down', 'Right', 'Up', 'Left', 'Up', 'Right', 'Down', 'Right', 'Down', 'Left', 'Up', 'Left', 'Down', 'Right', 'Up', 'Right', 'Down', 'Left', 'Left', 'Up', 'Right', 'Down', 'Left', 'Up', 'Up']\n",
      "Reached state: ((0, 0), ((0, 1, 2), (3, 4, 5), (6, 7, 8)))\n",
      "Is it goal? True\n"
     ]
    }
   ],
   "source": [
    "problem = PuzzleProblem()\n",
    "%timeit agent = DFSAgent(problem)\n",
    "agent = DFSAgent(problem)\n",
    "\n",
    "print(\"Plan lenght: \", len(agent.plan))\n",
    "\n",
    "print(\"Plan to be executed\", agent.plan)\n",
    "\n",
    "state = problem.initial_state\n",
    "while not problem.is_goal(state) and agent.plan:\n",
    "    action = agent.next_action(None)\n",
    "    state = problem.do_action(state, action)\n",
    "    \n",
    "print(\"Reached state:\", state)\n",
    "print(\"Is it goal?\", problem.is_goal(state))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n",
    "The pictures and the description of 8-puzzle are from \"Artificial Intelligence: A Modern Approach\" 3rd ed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
