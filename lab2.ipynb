{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Informed search - the A* algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depth-first search and breadth-first search considered in the previous lesson are completely *blind* algorithms: they're only concerned whether the currently considered state is a goal state or not. They're unable to distinguish whether a state is easy or hard to reach, or whether it is near or far of the goal. This makes them very inefficient search algorithms. To allievate the issue, we introduce informed search algorithms. The information is given to an algorithm in two ways:\n",
    "\n",
    "1. By using an *action cost* function $c(s,a)$, which, given a state $s$ and an action $a$ available in this state, returns its cost as a non-negative number.\n",
    "2. By using a *heuristic* $h(s)$, which, given a state, estimates the lowest cost to reach a goal state from the given state.\n",
    "\n",
    "Given a sequence of actions $a_1, \\ldots, a_n$ and an initial state $s_1$, we can express the *total cost* of reaching the state $s_{n+1}$ by executing the sequence as:\n",
    "$$ c(s_1, a_1, \\ldots, a_{n-1}) = \\sum_{i=1}^n c(s_i, a_i) $$\n",
    "and the *expected cost* of the solution as the sum of the total cost and the estimate cost of reaching the goal from the state $s_{n+1}$\n",
    "$$ f(s_1, a_1, \\ldots, a_n) = c(s_1, a_1, \\ldots, a_n) + h(s_{n+1}) $$\n",
    "\n",
    "The heuristic function is a bit tricky, because we want it to have two properties:\n",
    "* *Admissibility*: It must never *overestimate* the true cost of reaching the goal. \n",
    "* *Consistency*: Let $s$ be a state such that $a$ is an available action in this state and $s'$ is the state reached by executing this action. The heuristic should fulfil triangle inequality, that is, the estimated cost to reach the goal from $s$ should be no greater than the cost of executing the action $a$ + the estimated cost of reaching the goal from the new state.\n",
    "$$ h(s) \\leq c(s, a) + h(s') $$\n",
    "\n",
    "One can prove that admissibility follows from consistency, but consistency is important only if there are multiple paths to reach the same state (i.e., we are searching in a graph, not in a tree). Otherwise, admissability is sufficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets extend the class `Problem` from the previous lesson with two new functions `action_cost` and `heuristic`, which correspond to the functions $c(s,a)$ and $h(s)$ described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Problem:\n",
    "    @property\n",
    "    def initial_state(self):\n",
    "        ...\n",
    "        \n",
    "    def available_actions(self, state):\n",
    "        ...        \n",
    "        \n",
    "    def do_action(self, state, action):\n",
    "        ...\n",
    "        return new_state\n",
    "    \n",
    "    def is_goal(self, state) -> bool:\n",
    "        ...\n",
    "        \n",
    "    def action_cost(self, state, action) -> float:\n",
    "        ...\n",
    "        \n",
    "    def heuristic(self, state) -> float:\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make a concrete example, lets revisit the vacuum world. \n",
    "\n",
    "![](aima-images/fig2_2.png)\n",
    "\n",
    "Below, we assume a very simple model:\n",
    "* Any action costs 1. This corresponds to searching for the shortest plan.\n",
    "* The heuristic estimation is the number of fields which are still dirty. \n",
    "\n",
    "\n",
    "Lets consider the properties of the heuristic:\n",
    "* Is is admissible? The heuristic value is equal to the number of 'Suck' actions that are yet to be executed and ignores the spatial aspect (i.e., moving between the rooms), thus never overestimating.\n",
    "* Is it consistent? As a consequence of a single action the heuristic value can decrease by at most 1 (if the action happens to be 'Suck' and the room is dirty). The cost of any action is 1, so rewriting the triangle inequality we arrive at:\n",
    "$$ h(s) \\leq c(s, a) + h(s') = \\begin{cases} 1 + (h(s)-1) & a=\\text{'Suck' and the room was dirty} \\\\ 1 + h(s) & \\text{otherwise} \\end{cases} $$\n",
    "* Is it the best we could have? By no means! We could include the spatial aspect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VacuumProblem(Problem):\n",
    "    @property\n",
    "    def initial_state(self):\n",
    "        return (0, (True, True))\n",
    "    \n",
    "    def available_actions(self, state):\n",
    "        return [\"Left\", \"Suck\", \"Right\"]\n",
    "        \n",
    "    def do_action(self, state, action):\n",
    "        robot, dirty = state\n",
    "        if action == \"Left\":\n",
    "            return (max(robot-1, 0), dirty)\n",
    "        elif action == \"Suck\":\n",
    "            new_dirty = list(dirty)\n",
    "            new_dirty[robot] = False\n",
    "            return (robot, tuple(new_dirty))\n",
    "        elif action == \"Right\":\n",
    "            return (min(robot+1, len(dirty)-1), dirty)        \n",
    "        raise Exception('Invalid action')\n",
    "    \n",
    "    def is_goal(self, state) -> bool:\n",
    "        return not any(state[1])\n",
    "    \n",
    "    def action_cost(self, state, action):\n",
    "        return 1\n",
    "    \n",
    "    def heuristic(self, state):\n",
    "        return sum(state[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Implement the A* algorithm\n",
    "\n",
    "To implement the A* algorithm you must have a priority queue. Luckily, Python comes with one, so you don't need to implement it by yourself. Then, the algorithm is very simple: \n",
    "1. Start with a queue containing a single item - the initial state\n",
    "2. Repeat until the queue is not empty:\n",
    "  1. Pick an item with the lowest expected cost\n",
    "  2. If this is the goal, return the sequence of actions necessary to reach this state\n",
    "  3. Otherwise, for each available action, create a new entry in the queue corresponding to the state reached after executing the action.\n",
    "  \n",
    "Guard the algorithm against infinite loops: if you already visited a state, you don't need to visit it again (if your heuristic is consistent).\n",
    "\n",
    "In the cell below implement the algorithm in a similar manner as the BFS and DFS in the previous lesson: the sole argument is an object of the class Problem and the function should return a list of actions to achieve a goal state from the initial state.\n",
    "If it is impossible to reach the goal, return `None`.\n",
    "Count the number of states visited during the search and print in out before returning from the function, it will be useful later on to compare different heuristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from queue import PriorityQueue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def astar(problem: Problem):\n",
    "    queue = PriorityQueue()\n",
    "    current_state = problem.initial_state\n",
    "    path = ()\n",
    "    cumulative_costs = 0\n",
    "    visited_states_with_dist_from_start = {current_state:0}\n",
    "    expected_distance_from_goal = problem.heuristic(current_state) + cumulative_costs\n",
    "    queue.put((expected_distance_from_goal, current_state, path, cumulative_costs))\n",
    "    count = 0\n",
    "    \n",
    "    while queue:\n",
    "        expected_distance_from_goal, current_state, path, cumulative_costs = queue.get()\n",
    "#         print(expected_distance_from_goal, cumulative_costs, path)\n",
    "        if problem.is_goal(current_state):\n",
    "#             print(len(visited_states_with_dist_from_start))\n",
    "#             print(count)\n",
    "            return path\n",
    "        \n",
    "        for action in problem.available_actions(current_state):\n",
    "            count += 1\n",
    "            next_state = problem.do_action(current_state, action)\n",
    "            new_path = list(path)\n",
    "            new_path.append(action)\n",
    "            new_cumulative_costs = cumulative_costs + problem.action_cost(current_state, action)\n",
    "            expected_distance_from_goal = problem.heuristic(next_state) + cumulative_costs\n",
    "#             print(\"\\t\", expected_distance_from_goal, new_cumulative_costs, new_path)\n",
    "\n",
    "            if next_state not in visited_states_with_dist_from_start.keys():\n",
    "                visited_states_with_dist_from_start.update({next_state:expected_distance_from_goal})\n",
    "            \n",
    "            elif expected_distance_from_goal < visited_states_with_dist_from_start[next_state]:\n",
    "                visited_states_with_dist_from_start[next_state] = expected_distance_from_goal\n",
    "            \n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "            queue.put((expected_distance_from_goal, next_state, tuple(new_path), new_cumulative_costs))\n",
    "                \n",
    "    \n",
    "    print(\"there is no solution for this problem\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets test your code in the vacuum world!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Suck', 'Right', 'Suck')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "astar(VacuumProblem())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Variants of the vacuum world\n",
    "\n",
    "Now lets consider a different take on the vacuum world in which the heuristic is not admissible and increases as the number of dirty fields decreases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Suck', 'Right', 'Suck')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class VacuumProblem1(VacuumProblem):\n",
    "    def action_cost(self, state, action):\n",
    "        return 1\n",
    "    \n",
    "    def heuristic(self, state):\n",
    "        return len(state[1]) - sum(state[1])\n",
    "    \n",
    "astar(VacuumProblem1())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And another in which heuristic grossly overestimates the cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Suck', 'Right', 'Suck')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class VacuumProblem2(VacuumProblem):\n",
    "    def action_cost(self, state, action):\n",
    "        return 1\n",
    "    \n",
    "    def heuristic(self, state):\n",
    "        return 10 * sum(state[1])\n",
    "    \n",
    "astar(VacuumProblem2())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Which of the three heuristic functions (`VacuumProblem`, `VacuumProblem1`, `VacuumProblem2`) is the best? Is it the expected answer given the properties of the heuristics? If not, explain why an unorthodox approach works better.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best one is the first one. The reason is that it is admissible and allows to perform low number of iterations needed to find a solution. The 3rd heuristic seems to be as good as the 1st one but it is because of little search space. The 3rd function is not admissible which means that A* combined with this heuristic does not guarantee the optimal solution which can be a drawback in some cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: 8-puzzle problem\n",
    "\n",
    "Recall the 8-puzzle problem from the previous lesson. Reuse your code and implement an extended version assuming that each action costs 1. Propose 3 (at least) admissible heuristics. This time don't change the initial state, your solution should be capable enough to solve this.\n",
    "\n",
    "![](aima-images/fig3_4.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PuzzleProblem(Problem):\n",
    "    @property\n",
    "    def initial_state(self):\n",
    "        \"\"\"1st component of state:\n",
    "        - the (row, col) of where the blank tile (the zero tile) is\n",
    "        2nd component:\n",
    "        -3x3 matrix representing the board and the arrangement of tiles\"\"\"\n",
    "        return (4,(7,2,4,5,0,6,8,3,1))\n",
    "    \n",
    "    def generate_feasible_initial_state(self):\n",
    "        state = (0, tuple(range(len(self.initial_state[1]))))\n",
    "        for _ in range(70):\n",
    "            action = random.choice(self.available_actions(state))\n",
    "            state = self.do_action(state, action)\n",
    "#         self.initial_state = state\n",
    "        return state\n",
    "        \n",
    "    def available_actions(self, state):\n",
    "        index_of_blank, board = state\n",
    "        possible_moves = []\n",
    "        dimension = int(sqrt(len(self.initial_state[1])))\n",
    "        \n",
    "        if index_of_blank//dimension - 1 >= 0:\n",
    "            possible_moves.append(\"Up\")\n",
    "        if index_of_blank//dimension + 1 <= dimension - 1:\n",
    "            possible_moves.append(\"Down\")\n",
    "        if index_of_blank%dimension - 1 >= 0:\n",
    "            possible_moves.append(\"Left\")\n",
    "        if index_of_blank%dimension + 1 <= dimension - 1:\n",
    "            possible_moves.append(\"Right\")\n",
    "        return possible_moves\n",
    "        \n",
    "    def do_action(self, state, action):\n",
    "        dimension = int(sqrt(len(self.initial_state[1])))\n",
    "        actions = {'Up': -dimension,\n",
    "                  'Down': dimension,\n",
    "                  'Right': 1,\n",
    "                  'Left': -1}\n",
    "        index_of_blank, board = state\n",
    "        new_index_of_blank = index_of_blank + actions[action]\n",
    "        new_board = list(board)\n",
    "        new_board[index_of_blank], new_board[new_index_of_blank] = new_board[new_index_of_blank], new_board[index_of_blank]\n",
    "        \n",
    "        new_state = (new_index_of_blank, tuple(new_board))\n",
    "        \n",
    "        return new_state\n",
    "    \n",
    "    def is_goal(self, state) -> bool:\n",
    "        return state == (0, tuple(range(len(state[1]))))\n",
    "        \n",
    "    def action_cost(self, state, action) -> float:\n",
    "        return 1.0\n",
    "        \n",
    "    def heuristic(self, state) -> float:\n",
    "#         number of misplaced tiles\n",
    "        index, board = state\n",
    "        \n",
    "        num_of_misplaces_tiles = -1\n",
    "        for index in range(len(board)):\n",
    "            if index != board[index]:\n",
    "                num_of_misplaces_tiles+=1\n",
    "        return float(num_of_misplaces_tiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prove that this heuristic is admissible.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This heuristic counts the number of misplaced tiles and substracts one. This heuristic is admissible because:\n",
    "1. Every action as long as it is not the final one, can decrease number of misplaced tiles by one.\n",
    "2. If there is just a one pair of misplaced tiles the heuristic returns 1 because of the substraction.\n",
    "3. If there would always exist a sequence of actions which can place one tile on a proper position per one action, the heuristic would be still admissible and because of the substraction it would not overestimate number of steps in the final stage when just two tiles are misplaced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PuzzleProblem1(PuzzleProblem):\n",
    "    def heuristic(self, state) -> float:     \n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prove that this heuristic is admissible.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 is trivially fulfilling the admissibility property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PuzzleProblem2(PuzzleProblem):\n",
    "    def heuristic(self, state) -> float:\n",
    "#         Manhattan distance\n",
    "        index, board = state\n",
    "        manhattan_dist = 0\n",
    "        dimension = int(sqrt(len(self.initial_state[1])))\n",
    "        for idx, tile in enumerate(board):\n",
    "            manhattan_dist += sum( (abs(idx//dimension - tile//dimension), #row of a current spot - row of a goal spot\n",
    "                                   abs(idx%dimension - tile%dimension)) )  #col of a current spot - col of a goal spot\n",
    "        return manhattan_dist/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prove that this heuristic is admissible.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manhattan distance divided by 2 is admissible because:\n",
    "1. One action is always involves two tiles which means that an action can decrease the cumulative distance by at moxt two.\n",
    "2. If every move can decrease cumulative distance by 2 then the cumulative manhattan distance returns twice the expected number of actions needed to solve a puzzle times 2.\n",
    "3. If the cumulative manhattan distance will be divided then it won't overestimate in situations when every move pushes both tiles towards their goals, which is not probable in reality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run your heuristics on the given problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "701 ms ± 39 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "CPU times: user 2.3 s, sys: 13.4 ms, total: 2.31 s\n",
      "Wall time: 2.31 s\n",
      "610 ms ± 1.61 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "\n",
      "Reached state: (0, (0, 1, 2, 3, 4, 5, 6, 7, 8))\n",
      "Plan lenght:  26\n",
      "Is it goal? True \n",
      "\n",
      "\n",
      "Reached state: (0, (0, 1, 2, 3, 4, 5, 6, 7, 8))\n",
      "Plan lenght:  26\n",
      "Is it goal? True \n",
      "\n",
      "\n",
      "Reached state: (0, (0, 1, 2, 3, 4, 5, 6, 7, 8))\n",
      "Plan lenght:  26\n",
      "Is it goal? True \n",
      "\n",
      "Is plan0==plan1? True\n",
      "Is plan0==plan2? False\n",
      "Is plan1==plan2? False\n"
     ]
    }
   ],
   "source": [
    "problem = PuzzleProblem()\n",
    "\n",
    "%timeit plan0 = astar(PuzzleProblem())\n",
    "plan0 = astar(PuzzleProblem())\n",
    "%time plan1 = astar(PuzzleProblem1())\n",
    "plan1 = astar(PuzzleProblem1())\n",
    "%timeit plan2 = astar(PuzzleProblem2())\n",
    "plan2 = astar(PuzzleProblem2())\n",
    "\n",
    "for plan_x in (plan0, plan1, plan2):\n",
    "    plan = list(plan_x)\n",
    "    state = problem.initial_state\n",
    "    while not problem.is_goal(state) and plan:\n",
    "        action = plan.pop(0)\n",
    "        state = problem.do_action(state, action)\n",
    "    \n",
    "    print(\"\\nReached state:\", state)\n",
    "    print(\"Plan lenght: \", len(plan_x))\n",
    "    print(\"Is it goal?\", problem.is_goal(state), '\\n')\n",
    "    \n",
    "# print(plan0)\n",
    "# print(plan1)\n",
    "# print(plan2)\n",
    "print(\"Is plan0==plan1?\", plan0 == plan1)\n",
    "print(\"Is plan0==plan2?\", plan0 == plan2)\n",
    "print(\"Is plan1==plan2?\", plan1 == plan2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Which of the heuristics is the best for this task? Why is that?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think that the Manhattan distance works the best because of the lowest average time amoung other heuristics and the fact that finds the optimal lenght solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n",
    "The pictures and the description of 8-puzzle are from \"Artificial Intelligence: A Modern Approach\" 3rd ed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, (0, 9, 13, 11, 3, 1, 8, 7, 4, 14, 15, 6, 2, 12, 10, 5))\n"
     ]
    }
   ],
   "source": [
    "seq = list(range(16))\n",
    "random.shuffle(seq)\n",
    "print((seq.index(0), tuple(seq)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HardcorePuzzleProblem1(PuzzleProblem1):\n",
    "    @property\n",
    "    def initial_state(self):\n",
    "        return (5, (1, 5, 2, 3, 8, 0, 4, 7, 14, 9, 6, 10, 12, 13, 15, 11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, (8, 2, 1, 3, 9, 4, 6, 0, 5, 10, 11, 7, 12, 13, 14, 15))\n"
     ]
    }
   ],
   "source": [
    "problem = HardcorePuzzleProblem1()\n",
    "print(problem.generate_feasible_initial_state())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.3 s, sys: 283 ms, total: 14.6 s\n",
      "Wall time: 14.6 s\n",
      "\n",
      "Reached state: (0, (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15))\n",
      "Plan lenght:  18\n",
      "Is it goal? True \n",
      "\n"
     ]
    }
   ],
   "source": [
    "problem = HardcorePuzzleProblem1()\n",
    "%time plan = astar(problem)\n",
    "# plan = astar(problem)\n",
    "\n",
    "plan_x = list(plan)\n",
    "state = problem.initial_state\n",
    "while not problem.is_goal(state) and plan_x:\n",
    "    action = plan_x.pop(0)\n",
    "    state = problem.do_action(state, action)\n",
    "    \n",
    "print(\"\\nReached state:\", state)\n",
    "print(\"Plan lenght: \", len(plan))\n",
    "print(\"Is it goal?\", problem.is_goal(state), '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
